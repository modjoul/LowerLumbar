{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Introduction to Modjoul Lower Lumbar Model\n",
    "_**The Modjoul Lower Lumbar Model detects bending, twisting, acceleration duration, degrees, and counts based upon various sensor values. In addition, it provides the Static and Dynamic Lower Lumbar scores as well.**_\n",
    "\n",
    "1. [Introduction](#1.-Introduction)\n",
    "2. [Preparing CSV](#2.-Preparing-CSV)\n",
    "3. [Method - 1 Using Endpoint](#3.-Using-Endpoint)<br>\n",
    "    3.1. [Creating model](#3.1.-Creating-Model)<br>\n",
    "    3.2. [Creating endpoint config](#3.2.-Creating-Endpoint-Config)<br>\n",
    "    3.3. [Creating endpoint](#3.3.-Creating-Endpoint)<br>\n",
    "    3.2. [Invoking endpoint](#3.4.-Invoking-Endpoint)<br>\n",
    "    3.2. [Deleting the Endpoint - Optional](#3.5.-Deleting-the-Endpoint---Optional)\n",
    "4. [Method - 2 Using batch transform job](#4.-Using-Batch-Transform-Job)\n",
    "5. [Model Output](#5.-Model-Output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "Jump start your ability to understand the type of Lower Lumbar risks in your operation.   Model output includes\n",
    "Bends:\n",
    "1.\tTotal Count\n",
    "2.\tTotal Duration\n",
    "3.\tNormal Bend\n",
    "4.\tBend with: Twist, Acceleration, Twist and Acceleration\n",
    "5.\tBend Count and Duration by Angle: 21⁰-30⁰, 31⁰-40⁰, 41⁰-50⁰, 51⁰-60⁰, 61⁰-70⁰, >70⁰\n",
    "6.\tTwists:\n",
    "7.\tCount\n",
    "8.\tTwist Angles: 15⁰-45⁰, >45⁰\n",
    "9.\t**Lumbar Scores**: <br>\n",
    "9.1. **Dynamic Lumbar Score**: Associated score that reflects the stress placed on the lower lumbar using ONLY counts of the bending and twisting activities <br>\n",
    "9.2. **Static Lumbar Score**: Associated score that reflects the stress placed on the lower lumbar using counts AND durations of the bending and twisting activities\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparing CSV\n",
    "Prepare a csv file that should and must contain at least the following sensor values as columns:<br>\n",
    "**altimeter, accelerometer (X,Y,Z-axis values), magnetometer (X,Y,Z-axis values), gyroscope (X,Y,Z-axis values)**. The X, Y, Z - axis are aligned such that +X points to left of the body, +Y points towards above the body and +Z points to the front of the body. The model is a best fit if the sensors placement is at the waist region (similar to the postion of belt buckle).<br><br>\n",
    "**GPS** sensor values are optional but can be provided in order to improve the accuracy of the model. GPS values should contain two columns **gpsSpeed and gpsCourse**, if they are available.\n",
    "<font color=\"red\">_**Each data point is considered at milisecond level i.e, 10 rows = 1 second worth data**_</font> <br><br>\n",
    "The CSV file should include header and the columnNames should be as below : <br>\n",
    "_**altimeter accelX accelY accelZ magnetoX magnetoY magnetoZ gyroX gyroY gyroZ gpsSpeed gpsCourse**_\n",
    "(last two columns are optional)\n",
    "\n",
    "**Note:** The request body size for the endpoint should not exceed 7 MB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('https://s3.amazonaws.com/sagemaker-sample-datasets/generic/sampleInput.csv')\n",
    "df.to_csv(\"sample.csv\",index=False)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Using Endpoint\n",
    "\n",
    "The model can be directly accessed via the console provided by AWS. However, for a more customized process one can access the model using the below code as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Creating Model\n",
    "To create a model, import boto3, sagemaker and get the arn of the model package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "role = sagemaker.get_execution_role()\n",
    "smmp = boto3.client('sagemakermp')\n",
    "modelName='<Input Model Name>' \n",
    "modelArn = 'Paste Model ARN>'\n",
    "createHeatIndexResponse = smmp.create_model(ModelName=modelName,\\\n",
    "                             Containers=[{'ModelPackageName': modelArn}],\\\n",
    "                             ExecutionRoleArn=role,\\\n",
    "                             EnableNetworkIsolation=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Creating Endpoint Config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configName='<Input Configuration Name>'\n",
    "instanceType = '<Input Instance Type>'\n",
    "createHeatIndexEndpointConfig = smmp.create_endpoint_config(EndpointConfigName = configName, ProductionVariants = [{'InstanceType':instanceType, 'InitialInstanceCount':1, 'ModelName':modelName, 'VariantName':'xyz'}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Creating Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpointName = '<Input Endpoint Name>'\n",
    "createHeatIndexEndpoint = smmp.create_endpoint(EndpointName = endpointName, EndpointConfigName = configName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Invoking Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime = boto3.Session().client('runtime.sagemaker')\n",
    "\n",
    "#Reading Input Data \n",
    "with open('sample.csv','rb') as f:\n",
    "    payload = f.read()\n",
    "\n",
    "response = runtime.invoke_endpoint(EndpointName = endpointName, ContentType = 'text/csv', Body = payload)\n",
    "result = response['Body'].read().decode()\n",
    "\n",
    "#Writing Output Data \n",
    "import json\n",
    "with open('sampleOutput.json','w') as f:\n",
    "    f.write(json.dumps(json.loads(result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. Deleting the Endpoint - Optional\n",
    "\n",
    "If you're ready to be done with this notebook, please run the delete_endpoint line in the cell below.  This will remove the hosted endpoint you created and avoid any charges from a stray instance being left on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker.Session().delete_endpoint(endpointName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Using Batch Transform Job\n",
    "\n",
    "Refer the below link for how to use batch transform job for getting inferences from a model\n",
    "[sagemaker batch transform job](https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-batch-transform.html#ex1-batch-transform-console)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "#inputLocation = '<S3 location for Input Data>'\n",
    "#outputLocation = '<S3 location for Output Data>'\n",
    "\n",
    "jobName = '<Input Job Name>'\n",
    "instanceType = '<Input Instance Type>\n",
    "\n",
    "# Initialize the transformer object\n",
    "transformer =sagemaker.transformer.Transformer(base_transform_job_name = jobName, model_name = modelName, instance_count=1, instance_type = instanceType, output_path = outputLocation)\n",
    "\n",
    "# To start a transform job:\n",
    "transformer.transform(inputLocation, content_type='text/csv', split_type='None')\n",
    "\n",
    "# Then wait until transform job is completed\n",
    "transformer.wait() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"./sampleOutput.json\",\"r\") as f:\n",
    "    sampleResponse =json.loads(f.read())\n",
    "sampleResponse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
